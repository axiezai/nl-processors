{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load in GazeCom labeled data for training `[x,y]` coordinates. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import natsort\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helper functions:    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_files(pattern):\n",
    "    \"\"\"\n",
    "    Extracts file in alphanumerical order that match the provided pattern\n",
    "    \"\"\"\n",
    "    if isinstance(pattern, list):\n",
    "        pattern = os.path.join(*pattern)\n",
    "        \n",
    "    files = natsort.natsorted(glob.glob(pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError('Pattern could not detect file(s)')\n",
    "        \n",
    "    return files\n",
    "\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "    if seed is None:\n",
    "        seed = np.random.choice(2 ** 32)\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if seed_torch:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "def seed_wworker(worker_id):\n",
    "    \"\"\"In case dataloader is used?\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def set_device():\n",
    "    \"\"\"Using GPU or CPU?\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "    if device != 'cuda':\n",
    "        print(\"WARNING: For this notebook to perform best, \"\n",
    "        \"if possible, in the menu under `Runtime` -> \"\n",
    "        \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DEVICE = set_device()\n",
    "SEED = 42\n",
    "set_seed(SEED)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('nl-processors': conda)"
  },
  "interpreter": {
   "hash": "eb8be277761d447a0e0b6c238d2c2028680d3d34ee89229561ba5f8717eea730"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}